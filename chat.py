import openai

# OpenAI-compatible vLLM ì„œë²„ ì„¤ì •
client = openai.OpenAI(
    base_url="http://15.165.34.159:8000/v1",  # vLLM ì„œë²„ ì£¼ì†Œ
    api_key="token-abc123",                 # Dockerì—ì„œ ì„¤ì •í•œ API í‚¤
)

# ëŒ€í™” ë©”ì‹œì§€ ì´ˆê¸°í™”
messages = [
    {"role": "system", "content": "You are a helpful assistant."}
]

print("ğŸ’¬qwen3 Chatbot (type 'exit' to quit)")
while True:
    user_input = input("ğŸ‘¤ You: ")
    if user_input.strip().lower() in {"exit", "quit"}:
        print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    messages.append({"role": "user", "content": user_input})

    # ì‘ë‹µ ìš”ì²­
    try:
        response = client.chat.completions.create(
            model="/models/qwen3-32b",
            messages=messages,
            temperature=0.7,
            max_tokens=512,
        )
        reply = response.choices[0].message.content
        print(f"ğŸ¤– Bot: {reply}")

        # ì‘ë‹µ ë©”ì‹œì§€ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        messages.append({"role": "assistant", "content": reply})
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

